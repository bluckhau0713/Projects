# Drone X project Main Program File 2022

# # Double '# #' are used for code comments and explanations
# Single '#' are used for commented code

# # OpenCV Real TIme Computer Vision Library/API
import cv2
# # MediaPipe Machine Learning for Computer Vision and Pose Estimation
import mediapipe as mp
import time
# # DJITello dedicated API for drone connection and control Licensed by MIT
from djitellopy import tello

import commands

CAMFOCALPOINT = 288
SHOULDERINCHES = 15


# # Approximation Functions for Pose Distinctions
def precise3(first, second, third):
    if second - 5 <= first <= second + 5 and third - 5 <= first <= third + 5:
        return True


def approximate3(first, second, third):
    if second - 10 <= first <= second + 10 and third - 10 <= first <= third + 10:
        return True


def approximate2(first, second):
    if second - 10 <= first <= second + 10:
        return True


def vague2(first, second):
    if second - 20 <= first <= second + 20:
        return True


# # MediaPipe drawing utilities to overlay graphics specific body landmarks over
# # visual inputs to make an outline of the person or persons in view.
# # mpPose is specific to body landmarks ranging 32 points from head to toe
mpDraw = mp.solutions.drawing_utils
mpPose = mp.solutions.pose
pose = mpPose.Pose()

com = commands.Commands()

# # mpHand is specific to the hands crating 20 points per hand for more detailed use of finger gestures
# mpHands = mp.solutions.hands
# hands = mpHands.Hands()

# # Video capture from laptop video feed
# cap = cv2.VideoCapture(0)

# # Time variables used for FPS and travel calculations
pTime = 0
count = 0

# # Creation of Drone object for interaction and connection to Drone X
drone = tello.Tello()
drone.connect()

# # Check Successful connection with battery check and print
print(drone.get_battery())

# # Establish connection to Drone X video feed
drone.streamon()

# # Conditional Statements for current state of Drone X operation
cont = True
droneInAir = False
followMode = False

landmarkDict = {}
# # Continuous loop for user interaction with Drone X
while cont:
    # # Successful connection and reading of Laptop video feed
    # success, img = cap.read()

    # # stores frames from video feed into img variable
    img = drone.get_frame_read().frame
    # img = drone.get_video_capture()
    # # resize stored img to a smaller size for processing and display
    img = cv2.resize(img, (360, 240))

    # # Display of Drone X video feed
    cv2.imshow("Image ", img)
    cv2.waitKey(1)

    # # Conversion of photo to RGB format and then passing it to the MediaPipe API
    # # to process the image and find body pose landmarks
    imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    # # Full body specific pose estimation processing
    results = pose.process(imgRGB)
    # # Hand specific pose estimation processing
    # resultsh = hands.process(imgRGB)

    # # Checks if results finds Full body Pose Landmarks and then does the following
    if results.pose_landmarks:
        # # draws Full body pose landmarks and connecting lines between landmark points
        mpDraw.draw_landmarks(img, results.pose_landmarks, mpPose.POSE_CONNECTIONS)

        # # FPS calculation and display on image
        cTime = time.time()
        fps = 1 / (cTime - pTime)
        pTime = cTime
        cv2.putText(img, str(int(fps)), (70, 50), cv2.FONT_HERSHEY_PLAIN, 3, (255, 255, 255), 3)

        # # Display of MediaPipe Processed Image
        cv2.imshow("Image", img)
        cv2.waitKey(1)

        # # Prints Full Body landmark information in X,Y,Z percentage format generated by MediaPipe
        # for pose in results.pose_landmarks:
        #   print(results.pose_landmarks)

        # # Creation of empty Landmark List
        lmList = []

        # # for loop to store each landmark's stored values into the Landmark list and convert the
        # # X,Y,Z percentage data into coordinate data with origin point in the top
        # # left corner of the displayed and processed image
        for ID, lm in enumerate(results.pose_landmarks.landmark):
            h, w, c = img.shape
            cx, cy, cz = int(lm.x*w), int(lm.y*h), int(lm.z)
            # print(id, " x:", cx, " y:", cy)
            lmList.append([ID, cx, cy, cz])

        # #List of References and Variables in Lay-mans Relational naming
        # #separated by X and Y coordinate value in Landmark List
        # #that correlate to the Landmark List against
        # #MediaPipe's Landmark Map

        landmarkDict.update({"noseX": lmList[0][1]})
        landmarkDict.update({"noseY": lmList[0][2]})

        # 2 is left eye
        # 5 is right eye

        # 7 is left ear
        # 8 is right ear
        landmarkDict.update({"leftShoulderX": lmList[11][1]})

        landmarkDict.update({"leftShoulderY": lmList[11][2]})

        landmarkDict.update({"rightShoulderX": lmList[12][1]})
        landmarkDict.update({"rightShoulderY": lmList[12][2]})

        landmarkDict.update({"leftElbowX": lmList[13][1]})
        landmarkDict.update({"leftElbowY": lmList[13][2]})

        landmarkDict.update({"rightElbowX": lmList[14][1]})
        landmarkDict.update({"rightElbowY": lmList[14][2]})

        landmarkDict.update({"leftWristX": lmList[15][1]})
        landmarkDict.update({"leftWristY": lmList[15][2]})

        landmarkDict.update({"rightWristX": lmList[16][1]})
        landmarkDict.update({"rightWristY": lmList[16][2]})

        landmarkDict.update({"leftHipX": lmList[23][1]})
        landmarkDict.update({"leftHipY": lmList[23][2]})

        landmarkDict.update({"rightHipX": lmList[24][1]})
        landmarkDict.update({"rightHipY": lmList[24][2]})

        # # CURRENT list of Drone X Command Structure statements for gesture recognition
        # # and responsive action from Drone X
        if not droneInAir:
            # # DRONE X TAKEOFF
            # if leftWristY < noseY and rightWristY < noseY:
            if com.drone_takeoff(landmarkDict):
                drone.takeoff()
                droneInAir = True
                drone.send_rc_control(0, 0, 0, 0)   # sent to ensure it does not keep spinning from the last session
                print("DRONE X TAKES OFF")

        elif not followMode and droneInAir:
            # print("perceived pixels: ", leftShoulderX - rightShoulderX)
            # # DRONE X STOPS MOVING
            if droneInAir and com.drone_lands(landmarkDict):
                drone.send_rc_control(0, 0, 0, 0)
                print("DRONE X LANDS")
                drone.land()
                cont = False

            # # DRONE X MOVES TO DRONE RIGHT, TO PERSON LEFT
            elif droneInAir and com.drone_right(landmarkDict):
                drone.move_right(50)
                print("DRONE X MOVES TO DRONE RIGHT, TO PERSON LEFT")

            # # DRONE X MOVES TO DRONE LEFT, TO PERSON RIGHT
            elif droneInAir and com.drone_left(landmarkDict):
                drone.move_left(50)
                print("DRONE X MOVES TO DRONE LEFT, TO PERSON RIGHT")

            # # DRONE X GO UP
            elif droneInAir and com.drone_up(landmarkDict):
                drone.move_up(30)
                print("DRONE X MOVES UP")

            # #DRONE X MOVES FORWARDS, TOWARDS PERSON
            elif droneInAir and com.drone_forward(landmarkDict):
                drone.move_forward(50)
                print("DRONE X MOVES FORWARD")

            # # DRONE X MOVES BACKWARDS, AWAY FROM PERSON
            elif droneInAir and com.drone_backwards(landmarkDict):
                drone.move_back(50)
                print("DRONE X MOVES BACKWARDS")

            # # DRONE X STARTS FOLLOW MODE
            elif droneInAir and com.drone_change_mode(landmarkDict):
                startingPixelsFront = landmarkDict["leftShoulderX"] - landmarkDict["rightShoulderX"]
                startingPixelsBack = landmarkDict["rightShoulderX"] - landmarkDict["leftShoulderX"]
                print("DRONE X STARTS FOLLOWING")
                print("startingPixelsFront =", startingPixelsFront)
                startingDistanceToUser = (SHOULDERINCHES * CAMFOCALPOINT)/startingPixelsFront  # in inches
                followMode = True

        # # DRONE X IN FOLLOW MODE
        elif followMode:
            # distance in between shoulders
            currentPixelsFront = landmarkDict["leftShoulderX"] - landmarkDict["rightShoulderX"]
            currentPixelsBack = landmarkDict["rightShoulderX"] - landmarkDict["leftShoulderX"]

            if currentPixelsFront != 0:
                currentDistanceToUser = (SHOULDERINCHES * CAMFOCALPOINT)/currentPixelsFront  # in inches
            # print("distance =", currentDistanceToUser, "inches   drone height =", drone.get_height())

            # # GET MIDDLE OF IMAGE
            height, width = img.shape[0:2]
            mid = width/2
            midHeight = height/2

            # # DRONE X LANDS
            if droneInAir and com.drone_lands(landmarkDict):
                drone.send_rc_control(0, 0, 0, 0)
                print("DRONE X LANDS")
                drone.land()
                cont = False

#############################################################################################
            # # USER IS LEFT OF THE DRONE
            if com.drone_follow_left(landmarkDict, mid):
                drone.send_rc_control(0, 0, 0, 30)
                print("DRONE X ROTATE CLOCKWISE")

            # # USER IS RIGHT OF THE DRONE
            elif com.drone_follow_right(landmarkDict, mid):
                drone.send_rc_control(0, 0, 0, -30)
                print("DRONE X ROTATE COUNTER CLOCKWISE")

#############################################################################################
            # # USER IS TWO FOOT AWAY FROM THE STARTING POSITION
            elif currentDistanceToUser > (startingDistanceToUser + 24):
                drone.send_rc_control(0, 50, 0, 0)
                print("DRONE X FOLLOW FORWARD")

            # # USER IS TWO FOOT CLOSER TO THE STARTING POSITION
            elif currentDistanceToUser < (startingDistanceToUser - 24):
                drone.send_rc_control(0, -20, 0, 0)
                print("DRONE X FOLLOW backward")
#############################################################################################
            # # DRONE IS ABOVE USER SHOULDERS
            elif com.drone_follow_down(landmarkDict, midHeight):
                drone.send_rc_control(0, 0, -30, 0)
                print("DRONE X MOVES DOWN")

            # # DRONE IS BELOW USER SHOULDERS
            elif com.drone_follow_up(landmarkDict, midHeight):
                drone.send_rc_control(0, 0, 30, 0)
                print("DRONE X MOVES UP")
#############################################################################################
            # # DRONE SHOULD NOT MOVE
            elif com.drone_stop_moving(landmarkDict, mid, midHeight, startingDistanceToUser, currentDistanceToUser):
                drone.send_rc_control(0, 0, 0, 0)
#############################################################################################
            # # EXIT FOLLOW MODE
            if droneInAir and com.drone_change_mode(landmarkDict):
                followMode = False
                drone.send_rc_control(0, 0, 0, 0)
                print("DRONE X END FOLLOW MODE")
                time.sleep(3)

exit()


# MIT License
#
# Copyright (c) 2018 DAMIÀ FUENTES ESCOTÉ
#
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in
# all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
# THE SOFTWARE.